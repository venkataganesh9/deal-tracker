# .github/workflows/scraper.yml
name: Deal Tracker Automation

on:
  schedule:
    - cron: '0 */4 * * *'  # Every 4 hours at minute 0
  workflow_dispatch:        # Allow manual runs

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
      # Step 1: Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4
        
      # Step 2: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      # Step 3: Install Python dependencies
      - name: Install Python dependencies
        working-directory: ./scraper
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          playwright install chromium
          
      # Step 4: Run scraper
      - name: Scrape deals
        working-directory: ./scraper
        env:
          FIREBASE_SERVICE_ACCOUNT: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}
          AMAZON_ASSOCIATE_TAG: ${{ secrets.AMAZON_ASSOCIATE_TAG }}
        run: python main.py
        
      # Step 5: Set up Node.js
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          
      # Step 6: Install Firebase CLI
      - name: Install Firebase tools
        run: npm install -g firebase-tools
        
      # Step 7: Deploy to Firebase Hosting
      - name: Deploy to Firebase
        working-directory: ./frontend
        run: firebase deploy --only hosting --token ${{ secrets.FIREBASE_TOKEN }} --non-interactive